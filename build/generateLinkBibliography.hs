#!/usr/bin/env runghc
{-# LANGUAGE OverloadedStrings #-}
module Main where

-- Generate "link bibliographies" for Gwern.net pages.
--
-- Link bibliographies are similar to directory indexes in compiling a list of all links on a
-- Gwern.net page/essay, in order, with their annotations (where available). They are the
-- forward-citation dual of backlinks, are much easier to synoptically browse than mousing over
-- links one at a time, and can help provide a static version of the page (ie. download page + link
-- bibliography to preserve the annotations).
--
-- Link bibliographies are generated by parsing each $PAGE (provided in default.html as '$url$'),
-- filtering for Links using the Pandoc API, querying the metadata, generating a numbered list of
-- links, and then writing out the generated Markdown file to 'metadata/annotations/link-bibliography/$ESCAPED($PAGE).html'.
-- They are compiled like normal pages by Hakyll, and they are exposed to readers as an additional
-- link in the page metadata block, paired with the backlinks.

import Control.Monad (when)
import Data.List (isPrefixOf, isSuffixOf, nub, sort)
import Data.Text.Titlecase (titlecase)
import qualified Data.Map as M (lookup, keys)
import System.FilePath (takeDirectory, takeFileName)

import Data.Text.IO as TIO (readFile)
import qualified Data.Text as T (pack, unpack)
import System.Directory (doesFileExist)
import Control.Monad.Parallel as Par (mapM_)

import Text.Pandoc (Inline(Code, Link, Str, Space, Span, Strong), def, nullAttr, nullMeta, readMarkdown, readerExtensions, writerExtensions, runPure, pandocExtensions, ListNumberDelim(DefaultDelim), ListNumberStyle(LowerAlpha), Block(Para, OrderedList), Pandoc(..), writeHtml5String)
import Text.Pandoc.Walk (walk)

import LinkBacklink (getBackLinkCheck, getSimilarLinkCheck, getLinkBibLink)
import LinkMetadata (generateAnnotationTransclusionBlock, readLinkMetadata, authorsTruncate, hasAnnotation)
import LinkMetadataTypes (Metadata, MetadataItem)
import Query (extractURLs, extractLinks)
import Typography (typographyTransform)
import Utils (writeUpdatedFile, replace, printRed)
import Interwiki (convertInterwikiLinks)

main :: IO ()
main = do
  md <- readLinkMetadata
  -- build HTML fragments for each page or annotation link, containing just the list and no header/full-page wrapper, so they are nice to transclude *into* popups:
  Par.mapM_ (writeLinkBibliographyFragment md) $ M.toList md

-- don't waste the user's time if the annotation is not heavily linked, as most are not, or if all the links are WP links:
mininumLinkBibliographyFragment :: Int
mininumLinkBibliographyFragment = 3

writeLinkBibliographyFragment :: Metadata -> FilePath -> IO ()
writeLinkBibliographyFragment _ (_, (_,_,_,_,_,"")) = return ()
writeLinkBibliographyFragment md (path, (_,_,_,_,_,abstract)) = do
  let self = takeWhile (/='#') path
      selfAbsolute = "https://www.gwern.net"++self
  -- toggle between parsing the full original Markdown page, and just the annotation abstract:
  linksRaw <- if head self == '/' && '.'`notElem`path then
                if '#' `elem` path && abstract=="" then return [] -- if it's just an empty annotation triggered by a section existing, ignore
                else extractLinksFromPage (tail self ++ ".page")
              else return $ map T.unpack $ extractLinks False (T.pack abstract)
  -- delete self-links, such as in the ToC of scraped abstracts, or newsletters linking themselves as the first link (eg '/newsletter/2022/05' will link to 'https://www.gwern.net/newsletter/2022/05' at the beginning)
  let links = filter (\l -> not (self `isPrefixOf` l || selfAbsolute `isPrefixOf` l)) linksRaw
  when (length (filter (\l -> not ("https://en.wikipedia.org/wiki/" `isPrefixOf` l))  links) >= mininumLinkBibliographyFragment) $
    do backlinks    <- mapM (fmap snd . getBackLinkCheck) links
        similarlinks <- mapM (fmap snd . getSimilarLinkCheck) links
        let annotations = map (\l -> M.lookupDefault ("","","","",[],"") l md) links
            pairs' = zip4 links annotations backlinks similarlinks
            body = [Para [Strong [Str "Link Bibliography"], Str ":"], generateLinkBibliographyItems pairs']
            document = Pandoc nullMeta body
            html = runPure $ writeHtml5String def{writerExtensions = pandocExtensions} $
              walk typographyTransform $ walk convertInterwikiLinks $ walk (hasAnnotation md) document
        case html of
          Left e   -> printRed (show e)
          -- compare with the old version, and update if there are any differences:
          Right p' -> do let (path',_) = getLinkBibLink path
                        when (path' == "") $ error ("generateLinkBibliography.hs: writeLinkBibliographyFragment: writing out failed because received empty path' from getLinkBibLink for original path: " ++ path)
                        writeUpdatedFile "link-bibliography-fragment" path' p'

generateLinkBibliographyItems :: [(String,MetadataItem,FilePath,FilePath)] -> Block
generateLinkBibliographyItems [] = Para []
generateLinkBibliographyItems items = OrderedList (1, LowerAlpha, DefaultDelim) $ map generateLinkBibliographyItem items
generateLinkBibliographyItem  :: (String,MetadataItem,FilePath,FilePath) -> [Block]
generateLinkBibliographyItem (f,(t,aut,_,_,_,""),_,_)  = -- short:
  let f'
        | "http" `isPrefixOf` f = f
        | "index" `isSuffixOf` f = takeDirectory f
        | otherwise = takeFileName f
      authorShort = authorsTruncate aut
      authorSpan  = if authorShort/=aut then Span ("",["full-authors-list"],[("title", T.pack aut)]) . pure else id
      author = if aut=="" || aut=="N/A" then []
               else
                 [Str ",", Space, authorSpan (Str (T.pack authorShort))]
      -- I skip date because files don't usually have anything better than year, and that's already encoded in the filename which is shown
      linkAttr = if "https://en.wikipedia.org/wiki/" `isPrefixOf` f then ("",["include-annotation", "include-spinner-not"],[]) else nullAttr
      title = if t=="" then [Code nullAttr (T.pack f')] else [Str "“", Str (T.pack $ titlecase t), Str "”"]
  in [Para (Link linkAttr title (T.pack f, "") : author)]
-- long items:
generateLinkBibliographyItem (f,a,bl,sl) = generateAnnotationTransclusionBlock (f,a) bl sl ""

extractLinksFromPage :: String -> IO [String]
extractLinksFromPage path = fmap (fromMaybe []) $ runMaybeT $ do
  Right f <- try $ TIO.readFile path
  Right p <- pure $ runPure $ readMarkdown def{readerExtensions=pandocExtensions} f
  -- make the list unique, but keep the original ordering
  pure $ map (replace "https://www.gwern.net/" "/") $
    filter (\l -> head l /= '#') $ -- self-links are not useful in link bibliographies
    nub $ map T.unpack $ extractURLs p -- TODO: maybe extract the title from the metadata for nicer formatting?